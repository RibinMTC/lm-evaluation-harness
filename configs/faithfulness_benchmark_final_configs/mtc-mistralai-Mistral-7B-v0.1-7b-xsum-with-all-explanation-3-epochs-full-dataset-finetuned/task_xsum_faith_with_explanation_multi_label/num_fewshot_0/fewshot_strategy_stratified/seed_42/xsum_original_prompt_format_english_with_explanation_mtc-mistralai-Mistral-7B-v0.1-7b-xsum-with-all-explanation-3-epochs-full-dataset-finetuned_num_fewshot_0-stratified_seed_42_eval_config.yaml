batch_size: '4'
check_integrity: false
data_sampling: null
decontamination_ngrams_path: null
description_dict_path: null
device: null
end_range: null
fewshot_sampling: stratified
model: hf-causal-experimental
model_args: pretrained=mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-all-explanation-3-epochs-full-dataset-finetuned,trust_remote_code=False,use_accelerate=True,dtype=bfloat16,load_in_8bit=False,attn_implementation=flash_attention_2,max_length=4096
no_cache: true
num_fewshot: 0
output_base_path: results
output_path: null
seed: 42
start_range: null
task_configs:
-   prompt_template: configs/prompt_templates/faithfulness_benchmark_final_swisstext23_with_explanation_multi_label.json
    prompt_version: xsum_original_prompt_format_english_with_explanation
    task_name: xsum_faith_with_explanation_multi_label
wandb_on: true
write_out: true
