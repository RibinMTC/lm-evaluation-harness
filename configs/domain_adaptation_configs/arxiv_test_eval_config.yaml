batch_size: '8'
check_integrity: false
data_sampling: null
decontamination_ngrams_path: null
description_dict_path: null
device: null
fewshot_sampling: random
start_range: null
end_range: 20
model: hf-causal-experimental
model_args: pretrained=meta-llama/Llama-2-70b-chat-hf,trust_remote_code=False,use_accelerate=True,load_in_8bit=False,dtype=bfloat16,use_flash_attention_2=True
no_cache: true
num_fewshot: 0
output_base_path: results
output_path: null
prompt_version_per_task: default
seed: 42
tasks: arxiv_domain_adaptation_summarization
wandb_on: true
wandb_project_name: "domain_adaptation"
write_out: true
